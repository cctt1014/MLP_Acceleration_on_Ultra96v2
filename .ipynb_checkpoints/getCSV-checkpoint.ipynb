{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'weights_files/fit_transform_model_weights_Tuesday_week_13.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ee2676762be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Read H5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights_files/fit_transform_model_weights_Tuesday_week_13.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Get and print list of datasets within the H5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdatasetNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xilinx/.local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xilinx/.local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'weights_files/fit_transform_model_weights_Tuesday_week_13.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Read H5 file\n",
    "f = h5.File(\"weights_files/fit_transform_model_weights_Tuesday_week_13.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = list(f.keys())\n",
    "\n",
    "content = []\n",
    "\n",
    "for k1 in f:\n",
    "    print(k1)\n",
    "    for k2 in f[k1].keys():\n",
    "        print(k2)\n",
    "        for k3 in f[k1][k2].keys():  \n",
    "            print(k3)\n",
    "            \n",
    "            data = list(f[k1][k2][k3])\n",
    "            length = len(data)\n",
    "            print(f[k1][k2][k3].value.shape)\n",
    "\n",
    "            if (isinstance(data[0], np.float32)):\n",
    "                for i in range(length):\n",
    "                    content.append(data[i]) \n",
    "            else:\n",
    "                for i in range(length):\n",
    "                    sub_length = len(data[i])\n",
    "                    sub_data = data[i]\n",
    "                    for j in range(sub_length):\n",
    "#                         print(sub_data[j])\n",
    "                        content.append(sub_data[j])\n",
    "                    \n",
    "                \n",
    "print(\"Total length: \")\n",
    "print(len(content))\n",
    "print(type(content[1]))\n",
    "\n",
    "                \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mlpv4_4_stdscaler.csv\", content, '%s', newline=',')\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv('mlpv2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant_dense_4\n",
      "  dense_4\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_4\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    post_activation_max:0\n",
      "    post_activation_min:0\n",
      "quant_dense_5\n",
      "  dense_5\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_5\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    post_activation_max:0\n",
      "    post_activation_min:0\n",
      "quant_dense_6\n",
      "  dense_6\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_6\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    post_activation_max:0\n",
      "    post_activation_min:0\n",
      "quant_dense_7\n",
      "  dense_7\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_7\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    pre_activation_max:0\n",
      "    pre_activation_min:0\n",
      "quantize_layer_1\n",
      "  quantize_layer_1\n",
      "    optimizer_step:0\n",
      "    quantize_layer_1_max:0\n",
      "    quantize_layer_1_min:0\n",
      "Total length: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Take quantization into consideration\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read H5 file\n",
    "f = h5.File(\"weights_files/MLPmodel_Week13_NoFeature_QAware.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = list(f.keys())\n",
    "\n",
    "content = []\n",
    "\n",
    "for k1 in f:\n",
    "    print(k1)\n",
    "    for k2 in f[k1].keys():\n",
    "        print(\"  \"+k2)\n",
    "        for k3 in f[k1][k2].keys(): \n",
    "            print(\"    \"+k3)\n",
    "#             print(f[k1][k2][k3].value)\n",
    "            \n",
    "#             data = list(f[k1][k2][k3])\n",
    "#             length = len(data)\n",
    "#             print(f[k1][k2][k3].value.shape)\n",
    "            \n",
    "#             if (isinstance(data[0], np.float32)):\n",
    "#                 for i in range(length):\n",
    "#                     content.append(data[i]) \n",
    "#             else:\n",
    "#                 for i in range(length):\n",
    "#                     sub_length = len(data[i])\n",
    "#                     sub_data = data[i]\n",
    "#                     for j in range(sub_length):\n",
    "#                         content.append(sub_data[j])\n",
    "       \n",
    "print(\"Total length: \")\n",
    "print(len(content))\n",
    "\n",
    "data = {'params': content}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant_dense_4\n",
      "  dense_4\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_4\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    post_activation_max:0\n",
      "    post_activation_min:0\n",
      "quant_dense_5\n",
      "  dense_5\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_5\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    post_activation_max:0\n",
      "    post_activation_min:0\n",
      "quant_dense_6\n",
      "  dense_6\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_6\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    post_activation_max:0\n",
      "    post_activation_min:0\n",
      "quant_dense_7\n",
      "  dense_7\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_7\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    pre_activation_max:0\n",
      "    pre_activation_min:0\n",
      "quantize_layer_1\n",
      "  quantize_layer_1\n",
      "    optimizer_step:0\n",
      "    quantize_layer_1_max:0\n",
      "    quantize_layer_1_min:0\n",
      "Total length: \n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:23: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-0.05516023, -0.24711801,  0.06913034, -0.0073357 , -0.0852993 ,\n",
       "        -0.16376986, -0.19611603,  0.23834187,  0.007591  ,  0.0028917 ,\n",
       "         0.04195197, -0.09352348, -0.05614848,  0.02523417, -0.02499572,\n",
       "        -0.13503571,  0.07809229, -0.17361465,  0.06186342, -0.02139212,\n",
       "        -0.0537903 , -0.06089918, -0.01639524,  0.1504816 , -0.17228553,\n",
       "        -0.0810688 , -0.00537568,  0.00943929, -0.14631057, -0.11913352,\n",
       "        -0.12669107,  0.22457244,  0.07859904, -0.04203619, -0.00184337,\n",
       "        -0.26809335, -0.1876224 , -0.10576717,  0.08490039,  0.07102451,\n",
       "        -0.11437171, -0.14693582, -0.27895474, -0.03774743, -0.11219928,\n",
       "         0.06320448, -0.13194522,  0.00769071,  0.00604382, -0.14072323,\n",
       "        -0.14723647, -0.0483052 ,  0.0513929 , -0.13011754, -0.18162562,\n",
       "        -0.26534352, -0.17482345, -0.09953698, -0.1198805 , -0.2623506 ,\n",
       "         0.02445193,  0.03041092, -0.01800648, -0.01446345, -0.10654497,\n",
       "        -0.28103822, -0.22176184, -0.01816429, -0.16810566, -0.27029812,\n",
       "        -0.03038658, -0.22589244, -0.3762135 , -0.19621938, -0.04014535,\n",
       "        -0.24502449, -0.2517607 , -0.08977581, -0.22838308, -0.08200689,\n",
       "        -0.08831443, -0.13791732, -0.24789225, -0.126012  , -0.14411631,\n",
       "        -0.22251832, -0.02313016, -0.20806123, -0.20725192,  0.06323957,\n",
       "        -0.30052307, -0.04401628, -0.19178306, -0.11427584, -0.2245417 ,\n",
       "        -0.22831604, -0.15984257, -0.00213293, -0.13062577,  0.0067077 ,\n",
       "        -0.20489874, -0.09359815, -0.16625057,  0.09922117, -0.07622965,\n",
       "         0.06581133,  0.07064574, -0.20263131, -0.10451526, -0.02455035,\n",
       "         0.10250475, -0.2047959 , -0.15922749,  0.01225918, -0.21625225,\n",
       "         0.0024901 , -0.16727512,  0.07645024,  0.10649855, -0.18133584,\n",
       "        -0.06449815, -0.07996459,  0.07844105, -0.000386  , -0.02873133,\n",
       "        -0.12990147, -0.001985  ,  0.17719568], dtype=float32),\n",
       " array([ 0.17165628,  0.11046261,  0.3064835 ,  0.22186318,  0.01233702,\n",
       "        -0.08089657,  0.17023242,  0.03847547,  0.24505723,  0.3396959 ,\n",
       "         0.21386656, -0.0030579 , -0.0525502 ,  0.20852299, -0.00141878,\n",
       "         0.36214745,  0.1997592 ,  0.15884855,  0.29543233,  0.08223242,\n",
       "         0.26024103, -0.03076203,  0.2022509 ,  0.15591462, -0.04451123,\n",
       "         0.18991838,  0.09182879, -0.02300605,  0.23935771,  0.07997087,\n",
       "         0.01415963,  0.15953937, -0.09165833,  0.01584672,  0.2491297 ,\n",
       "         0.11086104,  0.18373145,  0.06733022,  0.3480101 ,  0.18330069,\n",
       "        -0.07033852,  0.25362724,  0.20394821, -0.00251215,  0.17504719,\n",
       "         0.40561548,  0.24446656,  0.23663983, -0.03530484,  0.11832265,\n",
       "         0.18254611,  0.10706898,  0.3125329 ,  0.10248699,  0.03415336,\n",
       "         0.19912349,  0.09096745,  0.21581273, -0.05293395,  0.14228168,\n",
       "        -0.05162855, -0.07811137,  0.06097272,  0.06726521], dtype=float32),\n",
       " array([ 0.09725267, -0.09868784,  0.4397466 ,  0.34064037,  0.03281512,\n",
       "         0.36049846,  0.46193144,  0.5367287 ,  0.15498164,  0.2966995 ,\n",
       "        -0.13512677, -0.10963102,  0.12783603,  0.26608527, -0.1067003 ,\n",
       "         0.03690744,  0.07094308,  0.10313788, -0.00396398,  0.5402956 ,\n",
       "         0.25550932,  0.17839284,  0.57106984,  0.1935265 ,  0.13253374,\n",
       "         0.3116794 ,  0.23346727,  0.09195573,  0.20059937,  0.00582123,\n",
       "         0.00695469,  0.18700644], dtype=float32),\n",
       " array([-0.09104911, -0.00457026,  0.03001426,  0.19097568, -0.11080037,\n",
       "        -0.36046666, -0.01468123, -0.09921846,  0.28487405], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take quantization into consideration\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read H5 file\n",
    "f = h5.File(\"weights_files/MLPmodel_Week13_NoFeature_QAware.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = list(f.keys())\n",
    "\n",
    "content = []\n",
    "bias_list = []\n",
    "weights_list = []\n",
    "weights_max = []\n",
    "weights_min = []\n",
    "\n",
    "for k1 in f:\n",
    "    print(k1)\n",
    "    for k2 in f[k1].keys():\n",
    "        print(\"  \"+k2)\n",
    "        for k3 in f[k1][k2].keys(): \n",
    "            print(\"    \"+k3)\n",
    "            if \"bias\" in k3:\n",
    "                bias_list.append(f[k1][k2][k3].value)\n",
    "            if \"kernel:0\" in k3\n",
    "                weights_list.append(f[k1][k2][k3].value)\n",
    "            \n",
    "                \n",
    "print(\"Total length: \")\n",
    "print(len(content))\n",
    "bias_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
