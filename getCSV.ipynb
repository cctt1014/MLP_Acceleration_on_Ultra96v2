{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_52\n",
      "dense_52\n",
      "bias:0\n",
      "(128,)\n",
      "kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:22: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 128)\n",
      "dense_53\n",
      "dense_53\n",
      "bias:0\n",
      "(64,)\n",
      "kernel:0\n",
      "(128, 64)\n",
      "dense_54\n",
      "dense_54\n",
      "bias:0\n",
      "(32,)\n",
      "kernel:0\n",
      "(64, 32)\n",
      "dense_55\n",
      "dense_55\n",
      "bias:0\n",
      "(9,)\n",
      "kernel:0\n",
      "(32, 9)\n",
      "Total length: \n",
      "41481\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Read H5 file\n",
    "f = h5.File(\"weights_files/MLPmodel_1hand_Week13.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = list(f.keys())\n",
    "\n",
    "content = []\n",
    "\n",
    "for k1 in f:\n",
    "    print(k1)\n",
    "    for k2 in f[k1].keys():\n",
    "        print(k2)\n",
    "        for k3 in f[k1][k2].keys():  \n",
    "            print(k3)\n",
    "            \n",
    "            data = list(f[k1][k2][k3])\n",
    "            length = len(data)\n",
    "            print(f[k1][k2][k3].value.shape)\n",
    "\n",
    "            if (isinstance(data[0], np.float32)):\n",
    "                for i in range(length):\n",
    "                    content.append(data[i]) \n",
    "            else:\n",
    "                for i in range(length):\n",
    "                    sub_length = len(data[i])\n",
    "                    sub_data = data[i]\n",
    "                    for j in range(sub_length):\n",
    "#                         print(sub_data[j])\n",
    "                        content.append(sub_data[j])\n",
    "                    \n",
    "                \n",
    "print(\"Total length: \")\n",
    "print(len(content))\n",
    "print(type(content[1]))\n",
    "\n",
    "                \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"mlpv4.csv\", content, '%s', newline=',')\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv('mlpv2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant_dense_4\n",
      "  dense_4\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_4\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    post_activation_max:0\n",
      "    post_activation_min:0\n",
      "quant_dense_5\n",
      "  dense_5\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_5\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    post_activation_max:0\n",
      "    post_activation_min:0\n",
      "quant_dense_6\n",
      "  dense_6\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_6\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    post_activation_max:0\n",
      "    post_activation_min:0\n",
      "quant_dense_7\n",
      "  dense_7\n",
      "    bias:0\n",
      "    kernel:0\n",
      "  quant_dense_7\n",
      "    kernel_max:0\n",
      "    kernel_min:0\n",
      "    optimizer_step:0\n",
      "    pre_activation_max:0\n",
      "    pre_activation_min:0\n",
      "quantize_layer_1\n",
      "  quantize_layer_1\n",
      "    optimizer_step:0\n",
      "    quantize_layer_1_max:0\n",
      "    quantize_layer_1_min:0\n",
      "Total length: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Take quantization into consideration\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read H5 file\n",
    "f = h5.File(\"weights_files/MLPmodel_Week13_NoFeature_QAware.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = list(f.keys())\n",
    "\n",
    "content = []\n",
    "\n",
    "for k1 in f:\n",
    "    print(k1)\n",
    "    for k2 in f[k1].keys():\n",
    "        print(\"  \"+k2)\n",
    "        for k3 in f[k1][k2].keys(): \n",
    "            print(\"    \"+k3)\n",
    "#             print(f[k1][k2][k3].value)\n",
    "            \n",
    "#             data = list(f[k1][k2][k3])\n",
    "#             length = len(data)\n",
    "#             print(f[k1][k2][k3].value.shape)\n",
    "            \n",
    "#             if (isinstance(data[0], np.float32)):\n",
    "#                 for i in range(length):\n",
    "#                     content.append(data[i]) \n",
    "#             else:\n",
    "#                 for i in range(length):\n",
    "#                     sub_length = len(data[i])\n",
    "#                     sub_data = data[i]\n",
    "#                     for j in range(sub_length):\n",
    "#                         content.append(sub_data[j])\n",
    "       \n",
    "print(\"Total length: \")\n",
    "print(len(content))\n",
    "\n",
    "data = {'params': content}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take quantization into consideration\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read H5 file\n",
    "f = h5.File(\"weights_files/MLPmodel_Week13_NoFeature_QAware.h5\", \"r\")\n",
    "# Get and print list of datasets within the H5 file\n",
    "datasetNames = list(f.keys())\n",
    "\n",
    "content = []\n",
    "bias_list = []\n",
    "\n",
    "for k1 in f:\n",
    "    print(k1)\n",
    "    for k2 in f[k1].keys():\n",
    "        print(\"  \"+k2)\n",
    "        for k3 in f[k1][k2].keys(): \n",
    "            print(\"    \"+k3)\n",
    "            if \"bias\" in k3:\n",
    "                bias_list.append(f[k1][k2][k3])\n",
    "            \n",
    "                \n",
    "print(\"Total length: \")\n",
    "print(len(content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
